{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antenna Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       网元标识  射频单元编号  小区本地ID\n",
      "0   6355826       2       6\n",
      "4   6355826       3       1\n",
      "8   6355826       0       4\n",
      "12  6355826       5       3\n",
      "16  6355826       1       5\n",
      "20  6355826       4       2\n",
      "24  6311444       1       2\n",
      "28  6311444       0       1\n",
      "32  6311444       2       3\n",
      "36  6355609       2       3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_antenna_planning_files(directory):\n",
    "    \"\"\"\n",
    "    读取指定目录中的天线安装规划文件，并规整列名，检查和删除重复行。\n",
    "\n",
    "    参数:\n",
    "    directory (str): 包含天线安装规划文件的目录路径。\n",
    "\n",
    "    返回值:\n",
    "    pd.DataFrame: 合并后的DataFrame，包含规整后的列名，并删除重复行。\n",
    "    \"\"\"\n",
    "    # 列出目录中的所有文件\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # 过滤出文件名包含“天线安装规划”关键字的CSV文件\n",
    "    antenna_files = [file for file in files if '天线安装规划' in file and file.endswith('.csv')]\n",
    "\n",
    "    # 定义要读取的列\n",
    "    columns_to_read = ['网元标识', '远端射频单元编号', '本地小区标识1']\n",
    "\n",
    "    # 初始化一个空的DataFrame列表\n",
    "    dfs = []\n",
    "\n",
    "    # 读取每个CSV文件并添加到DataFrame列表中\n",
    "    for file in antenna_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        df = pd.read_csv(file_path, encoding='gbk', usecols=columns_to_read)  # 根据需要调整编码格式\n",
    "        dfs.append(df)\n",
    "\n",
    "    # 合并所有DataFrame\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # 删除重复数据\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "\n",
    "    # 重命名列\n",
    "    combined_df.columns = ['网元标识', '射频单元编号', '小区本地ID']\n",
    "\n",
    "    # 检查和删除重复行\n",
    "    initial_row_count = combined_df.shape[0]\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "    final_row_count = combined_df.shape[0]\n",
    "\n",
    "    if initial_row_count != final_row_count:\n",
    "        print(f\"Removed {initial_row_count - final_row_count} duplicate rows.\")\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# 使用示例\n",
    "Datadir = r'C:\\Users\\zhuak\\Desktop\\Geography\\MobileData'\n",
    "df_AP = read_antenna_planning_files(Datadir)\n",
    "\n",
    "# 显示前10行数据\n",
    "print(df_AP.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radio Frequency Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      网元标识  射频单元编号   Longitude   Latitude\n",
      "0  6334965       2  110.744614  32.068618\n",
      "1  6334965       1  110.744614  32.068618\n",
      "2  6334965       0  110.744614  32.068618\n",
      "3  6337302       5  110.739594  32.053898\n",
      "4  6337302       3  110.739594  32.053898\n",
      "5  6337302       4  110.739594  32.053898\n",
      "6  6337302       1  110.739594  32.053898\n",
      "7  6337302       2  110.739594  32.053898\n",
      "8  6337302       0  110.739594  32.053898\n",
      "9  6337436       0  111.484500  32.541830\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_rf_planning_files(directory):\n",
    "    \"\"\"\n",
    "    读取指定目录中的射频单元规划文件，并规整列名，检查和删除重复行。\n",
    "\n",
    "    参数:\n",
    "    directory (str): 包含射频单元规划文件的目录路径。\n",
    "\n",
    "    返回值:\n",
    "    pd.DataFrame: 合并后的DataFrame，包含规整后的列名，并删除重复行。\n",
    "    \"\"\"\n",
    "    # 列出目录中的所有文件\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # 过滤出文件名包含“射频单元规划”关键字的CSV文件\n",
    "    rf_files = [file for file in files if '射频单元规划' in file and file.endswith('.csv')]\n",
    "\n",
    "    # 定义要读取的列\n",
    "    columns_to_read = ['网元标识', '射频单元编号', '射频单元RRU安装经度', '射频单元RRU安装纬度']\n",
    "\n",
    "    # 初始化一个空的DataFrame列表\n",
    "    dfs = []\n",
    "\n",
    "    # 读取每个CSV文件并添加到DataFrame列表中\n",
    "    for file in rf_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        df = pd.read_csv(file_path, encoding='gbk', usecols=columns_to_read)  # 根据需要调整编码格式\n",
    "        dfs.append(df)\n",
    "\n",
    "    # 合并所有DataFrame\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # 删除重复数据\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "\n",
    "    # 重命名列\n",
    "    combined_df.columns = ['网元标识', '射频单元编号', 'Longitude', 'Latitude']\n",
    "\n",
    "    # 检查和删除重复行\n",
    "    initial_row_count = combined_df.shape[0]\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "    final_row_count = combined_df.shape[0]\n",
    "\n",
    "    if initial_row_count != final_row_count:\n",
    "        print(f\"Removed {initial_row_count - final_row_count} duplicate rows.\")\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# 使用示例\n",
    "Datadir = r'C:\\Users\\zhuak\\Desktop\\Geography\\MobileData'\n",
    "df_RF = read_rf_planning_files(Datadir)\n",
    "\n",
    "# 显示前10行数据\n",
    "print(df_RF.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      网元标识  小区本地ID              小区友好名\n",
      "0  6334808       0    丹江农机驾校-D5H-2611\n",
      "1  6334808       5  丹江丹赵路郑家湾-D5H-2613\n",
      "2  6334808       4  丹江丹赵路郑家湾-D5H-2612\n",
      "3  6334808       3  丹江丹赵路郑家湾-D5H-2611\n",
      "4  6334936       0   房县解湾村委会-D5H-2611\n",
      "5  6334936       1   房县解湾村委会-D5H-2612\n",
      "6  6311642       3      通城灿良-D5H-2613\n",
      "7  6311642       2      通城灿良-D5H-2612\n",
      "8  6335023       2     林区小当阳-D5H-2613\n",
      "9  6334892       7    房县熊家凹2-D5H-2612\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_cell_planning_files(directory):\n",
    "    \"\"\"\n",
    "    读取指定目录中的小区规划文件，并规整列名，检查和删除重复行。\n",
    "\n",
    "    参数:\n",
    "    directory (str): 包含小区规划文件的目录路径。\n",
    "\n",
    "    返回值:\n",
    "    pd.DataFrame: 合并后的DataFrame，包含规整后的列名，并删除重复行。\n",
    "    \"\"\"\n",
    "    # 列出目录中的所有文件\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # 过滤出文件名包含“NR小区”关键字的CSV文件\n",
    "    cell_files = [file for file in files if 'NR小区' in file and file.endswith('.csv')]\n",
    "\n",
    "    # 定义要读取的列\n",
    "    columns_to_read = ['网元标识', '小区本地ID', '小区友好名']\n",
    "\n",
    "    # 初始化一个空的DataFrame列表\n",
    "    dfs = []\n",
    "\n",
    "    # 读取每个CSV文件并添加到DataFrame列表中\n",
    "    for file in cell_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        df = pd.read_csv(file_path, encoding='gbk', usecols=columns_to_read)  # 根据需要调整编码格式\n",
    "        dfs.append(df)\n",
    "\n",
    "    # 合并所有DataFrame\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # 删除重复数据\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "\n",
    "    # 重命名列\n",
    "    combined_df.columns = ['网元标识', '小区本地ID', '小区友好名']\n",
    "\n",
    "    # 检查和删除重复行\n",
    "    initial_row_count = combined_df.shape[0]\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "    final_row_count = combined_df.shape[0]\n",
    "\n",
    "    if initial_row_count != final_row_count:\n",
    "        print(f\"Removed {initial_row_count - final_row_count} duplicate rows.\")\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# 使用示例\n",
    "Datadir = r'C:\\Users\\zhuak\\Desktop\\Geography\\MobileData'\n",
    "df_CP = read_cell_planning_files(Datadir)\n",
    "\n",
    "# 显示前10行数据\n",
    "print(df_CP.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read HuBei MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OBJECTID SJGZQYMC DSJGZQYMC QXJGZQYMC XZJGZQYMC CJGZQYMC  SHAPE_AREA  \\\n",
      "0     576.0      湖北省       宜昌市  长阳土家族自治县      都镇湾镇     杨柘坪村    0.001183   \n",
      "1     577.0      湖北省       宜昌市  长阳土家族自治县      都镇湾镇     龙潭坪村    0.001642   \n",
      "2     578.0      湖北省       宜昌市  长阳土家族自治县      都镇湾镇     立志坪村    0.002743   \n",
      "3     579.0      湖北省       宜昌市  长阳土家族自治县      都镇湾镇     雪山河村    0.003297   \n",
      "4     580.0      湖北省       宜昌市  长阳土家族自治县      都镇湾镇     杜家冲村    0.001725   \n",
      "5     581.0      湖北省       宜昌市  长阳土家族自治县      都镇湾镇     五尖山村    0.001821   \n",
      "6     582.0      湖北省       宜昌市  长阳土家族自治县      都镇湾镇      麻池村    0.002221   \n",
      "7     583.0      湖北省       宜昌市  长阳土家族自治县      都镇湾镇      西湾村    0.000692   \n",
      "8     584.0      湖北省       宜昌市  长阳土家族自治县      都镇湾镇      重溪村    0.001702   \n",
      "9     585.0      湖北省       宜昌市  长阳土家族自治县      都镇湾镇     朱栗山村    0.001061   \n",
      "\n",
      "   SHAPE_LEN                                           geometry  \n",
      "0   0.240019  MULTIPOLYGON (((110.99976 30.33573, 110.99901 ...  \n",
      "1   0.260185  MULTIPOLYGON (((110.92990 30.36015, 110.93130 ...  \n",
      "2   0.290204  MULTIPOLYGON (((110.92364 30.31976, 110.92359 ...  \n",
      "3   0.384741  MULTIPOLYGON (((110.92957 30.28948, 110.92979 ...  \n",
      "4   0.278101  MULTIPOLYGON (((110.98930 30.28638, 110.98946 ...  \n",
      "5   0.240321  MULTIPOLYGON (((110.96538 30.33598, 110.96523 ...  \n",
      "6   0.270690  MULTIPOLYGON (((110.82810 30.41101, 110.83152 ...  \n",
      "7   0.136250  MULTIPOLYGON (((110.78551 30.40236, 110.79116 ...  \n",
      "8   0.266182  MULTIPOLYGON (((110.79249 30.38666, 110.79351 ...  \n",
      "9   0.192487  MULTIPOLYGON (((110.82163 30.34787, 110.82219 ...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "def read_hubei_map_files(directory, filename):\n",
    "    \"\"\"\n",
    "    读取指定目录中的湖北Map文件。\n",
    "\n",
    "    参数:\n",
    "    directory (str): 包含湖北Map文件的目录路径。\n",
    "    filename (str): 湖北Map文件的文件名。\n",
    "\n",
    "    返回值:\n",
    "    gpd.GeoDataFrame: 读取的GeoDataFrame。\n",
    "    \"\"\"\n",
    "    # 构建文件路径\n",
    "    file_path = os.path.join(directory, filename)\n",
    "\n",
    "    # 读取GeoJSON文件\n",
    "    gdf = gpd.read_file(file_path)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "# 使用示例\n",
    "GosDir = r'C:\\Users\\zhuak\\Desktop\\Geography'\n",
    "gdffile = '湖北省村级边界.geojson'\n",
    "gdf = read_hubei_map_files(GosDir, gdffile)\n",
    "\n",
    "# 显示前10行数据\n",
    "print(gdf.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         网元标识  小区本地ID                小区友好名   Longitude   Latitude   省份   地市  \\\n",
      "0     6334965       0     房县小草咖啡1-D5H-2611  110.744614  32.068618  湖北省  十堰市   \n",
      "1     6334965       1     房县小草咖啡1-D5H-2612  110.744614  32.068618  湖北省  十堰市   \n",
      "574   6334987       1     房县小草咖啡2-D5H-2612  110.744426  32.065918  湖北省  十堰市   \n",
      "575   6334987       0     房县小草咖啡2-D5H-2611  110.744426  32.065918  湖北省  十堰市   \n",
      "3876  6337299       3      房县滨河花园-D5H-2611  110.743071  32.062452  湖北省  十堰市   \n",
      "3877  6337299       4      房县滨河花园-D5H-2612  110.743071  32.062452  湖北省  十堰市   \n",
      "2     6337302       0       房县劳动局-D5H-2611  110.739594  32.053898  湖北省  十堰市   \n",
      "3     6337302       5  房县联关(凤凰山路)-D5H-2613  110.739594  32.053898  湖北省  十堰市   \n",
      "4     6337302       3  房县联关(凤凰山路)-D5H-2611  110.739594  32.053898  湖北省  十堰市   \n",
      "5     6337302       4  房县联关(凤凰山路)-D5H-2612  110.739594  32.053898  湖北省  十堰市   \n",
      "\n",
      "      县区   镇区    村区  \n",
      "0     房县  城关镇  北关社区  \n",
      "1     房县  城关镇  北关社区  \n",
      "574   房县  城关镇  北关社区  \n",
      "575   房县  城关镇  北关社区  \n",
      "3876  房县  城关镇  北关社区  \n",
      "3877  房县  城关镇  北关社区  \n",
      "2     房县  城关镇  老城社区  \n",
      "3     房县  城关镇  老城社区  \n",
      "4     房县  城关镇  老城社区  \n",
      "5     房县  城关镇  老城社区  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def process_rf_ap_cp(df_ap, df_rf, df_cp, gdf):\n",
    "    \"\"\"\n",
    "    合并天线规划数据、射频单元规划数据和小区规划数据，并与地理数据进行空间连接。\n",
    "\n",
    "    参数:\n",
    "    df_ap (pd.DataFrame): 天线规划数据。\n",
    "    df_rf (pd.DataFrame): 射频单元规划数据。\n",
    "    df_cp (pd.DataFrame): 小区规划数据。\n",
    "    gdf (gpd.GeoDataFrame): 地理数据。\n",
    "\n",
    "    返回值:\n",
    "    gpd.GeoDataFrame: 合并后的GeoDataFrame，包含规整后的列名。\n",
    "    \"\"\"\n",
    "    # 合并天线规划数据和射频单元规划数据\n",
    "    df_rfap = pd.merge(df_ap, df_rf, how='inner', \n",
    "                       left_on=['网元标识', '射频单元编号'],\n",
    "                       right_on=['网元标识', '射频单元编号'],\n",
    "                       suffixes=('_df_AP', '_df_RF'))\n",
    "\n",
    "    # 选择并重命名列\n",
    "    df_rfap = df_rfap[['网元标识', '小区本地ID', '射频单元编号', 'Longitude', 'Latitude']]\n",
    "\n",
    "    # 合并射频单元规划数据和小区规划数据\n",
    "    df_rac = pd.merge(df_rfap, df_cp, how='inner', \n",
    "                      left_on=['网元标识', '小区本地ID'],\n",
    "                      right_on=['网元标识', '小区本地ID'],\n",
    "                      suffixes=('_df_RFAP', '_df_CP'))\n",
    "\n",
    "    # 选择并重命名列\n",
    "    df_rac = df_rac[['网元标识', '小区本地ID', '小区友好名', 'Longitude', 'Latitude']]\n",
    "\n",
    "    # 创建几何图形列表（点）\n",
    "    geometry = [Point(xy) for xy in zip(df_rac['Longitude'], df_rac['Latitude'])]\n",
    "\n",
    "    # 将 pandas DataFrame 转换为 GeoDataFrame\n",
    "    df_rac = gpd.GeoDataFrame(df_rac, geometry=geometry)\n",
    "\n",
    "    # 设置 CRS\n",
    "    if df_rac.crs is None:\n",
    "        df_rac = df_rac.set_crs(gdf.crs)\n",
    "\n",
    "    # 空间连接\n",
    "    gdf_rac = gpd.sjoin(df_rac, gdf, how='inner', predicate='within')\n",
    "\n",
    "    # 选择并重命名列\n",
    "    gdf_rac = gdf_rac[['网元标识', '小区本地ID', '小区友好名', 'Longitude', 'Latitude', 'SJGZQYMC', 'DSJGZQYMC', 'QXJGZQYMC', 'XZJGZQYMC', 'CJGZQYMC']].rename(\n",
    "        columns={'SJGZQYMC': '省份', 'DSJGZQYMC': '地市', 'QXJGZQYMC': '县区', 'XZJGZQYMC': '镇区', 'CJGZQYMC': '村区'}\n",
    "    )\n",
    "\n",
    "    return gdf_rac\n",
    "\n",
    "# 使用示例\n",
    "\n",
    "gdf_RAC = process_rf_ap_cp(df_AP, df_RF, df_CP, gdf)\n",
    "\n",
    "# 显示结果\n",
    "print(gdf_RAC.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read KPI file and Regular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目录中的所有文件: ['1one.csv', '700MNR小区(3100600).csv', '700M射频单元规划(3000322).csv', 'df_KPI_utf8.csv', 'DT_BBU功耗_FDD_20240904000000_20240911000000.CSV', 'DT_BBU功耗_TDD_20240904000000_20240911000000.CSV', 'DT_PowerBI指标通报计数器_FDD_20240904000000_20240911000000.CSV', 'DT_PowerBI指标通报计数器_TDD_20240904000000_20240911000000.CSV', 'DT_RRU功耗_FDD_20240904000000_20240911000000.CSV', 'DT_RRU功耗_TDD_20240904000000_20240911000000.CSV', 'FDD天线安装规划(3000323).csv', 'TDDNR小区(3100600).csv', 'TDD天线安装规划(3000323).csv', 'TDD射频单元规划(3000322).csv']\n",
      "过滤出的文件: ['DT_PowerBI指标通报计数器_FDD_20240904000000_20240911000000.CSV', 'DT_PowerBI指标通报计数器_TDD_20240904000000_20240911000000.CSV']\n",
      "正在读取文件: C:\\Users\\zhuak\\Desktop\\Geography\\MobileData\\DT_PowerBI指标通报计数器_FDD_20240904000000_20240911000000.CSV\n",
      "成功读取文件: C:\\Users\\zhuak\\Desktop\\Geography\\MobileData\\DT_PowerBI指标通报计数器_FDD_20240904000000_20240911000000.CSV\n",
      "正在读取文件: C:\\Users\\zhuak\\Desktop\\Geography\\MobileData\\DT_PowerBI指标通报计数器_TDD_20240904000000_20240911000000.CSV\n",
      "成功读取文件: C:\\Users\\zhuak\\Desktop\\Geography\\MobileData\\DT_PowerBI指标通报计数器_TDD_20240904000000_20240911000000.CSV\n",
      "        NB nrCellCfg        开始时间        结束时间                Nr小区工作频段    MHz  \\\n",
      "0  6299318         1  2024-09-04  2024-09-05  band28(758~803MHz)(28)  30(5)   \n",
      "1  6299318         1  2024-09-05  2024-09-06  band28(758~803MHz)(28)  30(5)   \n",
      "2  6299318         1  2024-09-06  2024-09-07  band28(758~803MHz)(28)  30(5)   \n",
      "3  6299318         1  2024-09-07  2024-09-08  band28(758~803MHz)(28)  30(5)   \n",
      "4  6299318         1  2024-09-08  2024-09-09  band28(758~803MHz)(28)  30(5)   \n",
      "5  6299318         1  2024-09-09  2024-09-10  band28(758~803MHz)(28)  30(5)   \n",
      "6  6299318         1  2024-09-10  2024-09-11  band28(758~803MHz)(28)  30(5)   \n",
      "7  6299318         2  2024-09-04  2024-09-05  band28(758~803MHz)(28)  30(5)   \n",
      "8  6299318         2  2024-09-05  2024-09-06  band28(758~803MHz)(28)  30(5)   \n",
      "9  6299318         2  2024-09-06  2024-09-07  band28(758~803MHz)(28)  30(5)   \n",
      "\n",
      "   逻辑小区id  R2035_003  R2035_013  R2035_026  ...  R1001_001  R1001_004  \\\n",
      "0     1.0          1          1         46  ...       9884       2432   \n",
      "1     1.0          2          2         61  ...       9702       2508   \n",
      "2     1.0          3          3         74  ...      14232       3982   \n",
      "3     1.0          5          5        131  ...      17243       4610   \n",
      "4     1.0          2          2         53  ...      13964       4258   \n",
      "5     1.0          5          4         63  ...      10206       2876   \n",
      "6     1.0          3          3         63  ...      13395       3690   \n",
      "7     2.0         10         10        179  ...      24187       4855   \n",
      "8     2.0         13         13        210  ...      26347       6148   \n",
      "9     2.0          7          7        227  ...      28881       6504   \n",
      "\n",
      "   R1001_007  R1001_008  R1001_012  R1001_015  R1001_018  R1001_019  \\\n",
      "0         98          0       9848       2428         98          0   \n",
      "1        100          0       9668       2505        100          0   \n",
      "2        125          0      14185       3978        125          0   \n",
      "3        137          0      17172       4600        136          0   \n",
      "4        125          0      13883       4248        124          0   \n",
      "5         84          0      10166       2867         84          0   \n",
      "6        102          0      13332       3681        102          0   \n",
      "7        187          0      24102       4845        186          0   \n",
      "8        213          0      26267       6141        213          0   \n",
      "9        229          0      28773       6495        228          0   \n",
      "\n",
      "   K1009_001  K1009_002  \n",
      "0       7.47       0.21  \n",
      "1       5.65       0.36  \n",
      "2       8.54       0.32  \n",
      "3      11.19       0.60  \n",
      "4       6.63       0.36  \n",
      "5       3.54       0.20  \n",
      "6       4.52       0.30  \n",
      "7      15.42       0.56  \n",
      "8      14.45       0.69  \n",
      "9      17.00       0.80  \n",
      "\n",
      "[10 rows x 245 columns]\n",
      "目录中的所有文件: ['1one.csv', '700MNR小区(3100600).csv', '700M射频单元规划(3000322).csv', 'df_KPI_utf8.csv', 'DT_BBU功耗_FDD_20240904000000_20240911000000.CSV', 'DT_BBU功耗_TDD_20240904000000_20240911000000.CSV', 'DT_PowerBI指标通报计数器_FDD_20240904000000_20240911000000.CSV', 'DT_PowerBI指标通报计数器_TDD_20240904000000_20240911000000.CSV', 'DT_RRU功耗_FDD_20240904000000_20240911000000.CSV', 'DT_RRU功耗_TDD_20240904000000_20240911000000.CSV', 'FDD天线安装规划(3000323).csv', 'TDDNR小区(3100600).csv', 'TDD天线安装规划(3000323).csv', 'TDD射频单元规划(3000322).csv']\n",
      "过滤出的文件: ['DT_PowerBI指标通报计数器_FDD_20240904000000_20240911000000.CSV', 'DT_PowerBI指标通报计数器_TDD_20240904000000_20240911000000.CSV']\n",
      "正在读取文件: C:\\Users\\zhuak\\Desktop\\Geography\\MobileData\\DT_PowerBI指标通报计数器_FDD_20240904000000_20240911000000.CSV\n",
      "成功读取文件: C:\\Users\\zhuak\\Desktop\\Geography\\MobileData\\DT_PowerBI指标通报计数器_FDD_20240904000000_20240911000000.CSV\n",
      "正在读取文件: C:\\Users\\zhuak\\Desktop\\Geography\\MobileData\\DT_PowerBI指标通报计数器_TDD_20240904000000_20240911000000.CSV\n",
      "成功读取文件: C:\\Users\\zhuak\\Desktop\\Geography\\MobileData\\DT_PowerBI指标通报计数器_TDD_20240904000000_20240911000000.CSV\n",
      "        NB nrCellCfg        开始时间        结束时间                Nr小区工作频段    MHz  \\\n",
      "0  6299318         1  2024-09-04  2024-09-05  band28(758~803MHz)(28)  30(5)   \n",
      "1  6299318         1  2024-09-05  2024-09-06  band28(758~803MHz)(28)  30(5)   \n",
      "2  6299318         1  2024-09-06  2024-09-07  band28(758~803MHz)(28)  30(5)   \n",
      "3  6299318         1  2024-09-07  2024-09-08  band28(758~803MHz)(28)  30(5)   \n",
      "4  6299318         1  2024-09-08  2024-09-09  band28(758~803MHz)(28)  30(5)   \n",
      "5  6299318         1  2024-09-09  2024-09-10  band28(758~803MHz)(28)  30(5)   \n",
      "6  6299318         1  2024-09-10  2024-09-11  band28(758~803MHz)(28)  30(5)   \n",
      "7  6299318         2  2024-09-04  2024-09-05  band28(758~803MHz)(28)  30(5)   \n",
      "8  6299318         2  2024-09-05  2024-09-06  band28(758~803MHz)(28)  30(5)   \n",
      "9  6299318         2  2024-09-06  2024-09-07  band28(758~803MHz)(28)  30(5)   \n",
      "\n",
      "   逻辑小区id  R2035_003  R2035_013  R2035_026  ...  R1001_001  R1001_004  \\\n",
      "0     1.0          1          1         46  ...       9884       2432   \n",
      "1     1.0          2          2         61  ...       9702       2508   \n",
      "2     1.0          3          3         74  ...      14232       3982   \n",
      "3     1.0          5          5        131  ...      17243       4610   \n",
      "4     1.0          2          2         53  ...      13964       4258   \n",
      "5     1.0          5          4         63  ...      10206       2876   \n",
      "6     1.0          3          3         63  ...      13395       3690   \n",
      "7     2.0         10         10        179  ...      24187       4855   \n",
      "8     2.0         13         13        210  ...      26347       6148   \n",
      "9     2.0          7          7        227  ...      28881       6504   \n",
      "\n",
      "   R1001_007  R1001_008  R1001_012  R1001_015  R1001_018  R1001_019  \\\n",
      "0         98          0       9848       2428         98          0   \n",
      "1        100          0       9668       2505        100          0   \n",
      "2        125          0      14185       3978        125          0   \n",
      "3        137          0      17172       4600        136          0   \n",
      "4        125          0      13883       4248        124          0   \n",
      "5         84          0      10166       2867         84          0   \n",
      "6        102          0      13332       3681        102          0   \n",
      "7        187          0      24102       4845        186          0   \n",
      "8        213          0      26267       6141        213          0   \n",
      "9        229          0      28773       6495        228          0   \n",
      "\n",
      "   K1009_001  K1009_002  \n",
      "0       7.47       0.21  \n",
      "1       5.65       0.36  \n",
      "2       8.54       0.32  \n",
      "3      11.19       0.60  \n",
      "4       6.63       0.36  \n",
      "5       3.54       0.20  \n",
      "6       4.52       0.30  \n",
      "7      15.42       0.56  \n",
      "8      14.45       0.69  \n",
      "9      17.00       0.80  \n",
      "\n",
      "[10 rows x 245 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def read_and_process_kpi_files(directory, keyword='DT_PowerBI指标通报计数器_', file_extension='.csv'):\n",
    "    \"\"\"\n",
    "    读取指定目录中的KPI文件，合并、处理日期和字符串列、转换特定列的数据类型、提取列名中的代码，并删除重复行和特定列。\n",
    "\n",
    "    参数:\n",
    "    directory (str): 包含KPI文件的目录路径。\n",
    "    keyword (str): 文件名中包含的关键字，默认值为 'DT_PowerBI指标通报计数器_'。\n",
    "    file_extension (str): 文件扩展名，默认值为 '.csv'。\n",
    "\n",
    "    返回值:\n",
    "    pd.DataFrame: 处理后的DataFrame，包含所有读取的KPI数据，并删除了重复行。\n",
    "    \"\"\"\n",
    "    # 列出目录中的所有文件\n",
    "    files = os.listdir(directory)\n",
    "    print(f\"目录中的所有文件: {files}\")  # 调试信息\n",
    "\n",
    "    # 过滤出包含特定关键字的CSV文件\n",
    "    kpi_files = [file for file in files if keyword in file and file.lower().endswith(file_extension)]\n",
    "    print(f\"过滤出的文件: {kpi_files}\")  # 调试信息\n",
    "\n",
    "    # 初始化一个空的DataFrame列表\n",
    "    dfs = []\n",
    "\n",
    "    # 读取每个CSV文件并添加到DataFrame列表中\n",
    "    for file in kpi_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        print(f\"正在读取文件: {file_path}\")  # 调试信息\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, skiprows=2, header=0, encoding='cp936', na_values=[\"n/a\", \"na\", \"-\"])\n",
    "            df.columns = df.columns.str.replace(' ', '')  # 去除列名中的空格\n",
    "            dfs.append(df)\n",
    "            print(f\"成功读取文件: {file_path}\")  # 调试信息\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"读取文件时发生编码错误：{e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"读取文件时发生其他错误：{e}\")\n",
    "\n",
    "    # 检查是否成功读取了任何文件\n",
    "    if not dfs:\n",
    "        print(\"没有成功读取任何文件，请检查文件路径和过滤条件。\")\n",
    "        return pd.DataFrame()  # 返回空的DataFrame\n",
    "    else:\n",
    "        # 合并所有DataFrame\n",
    "        df_kpi = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "        # 删除重复行\n",
    "        df_kpi = df_kpi.drop_duplicates()\n",
    "\n",
    "        # 处理日期列\n",
    "        date_columns = ['开始时间', '结束时间']\n",
    "        for column_date in date_columns:\n",
    "            df_kpi[column_date] = df_kpi[column_date].astype(str).str.split().str[0]\n",
    "            df_kpi[column_date] = pd.to_datetime(df_kpi[column_date], errors='coerce')\n",
    "            df_kpi[column_date] = df_kpi[column_date].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        # 拆分字符串列\n",
    "        df_kpi[[\"小区名称\", \"Other\"]] = df_kpi[\"对象\"].str.split('\\(g', n=1, expand=True)\n",
    "        df_kpi[[\"NB\", \"nrCellCfg\"]] = df_kpi[\"Other\"].str.split(',', n=1, expand=True)\n",
    "        df_kpi[\"NB\"] = df_kpi[\"NB\"].str.lstrip('NB=')\n",
    "        df_kpi[\"nrCellCfg\"] = df_kpi[\"nrCellCfg\"].str.lstrip('nrCellCfg=').str.rstrip(')')\n",
    "        df_kpi.drop(columns=[\"对象\", \"Other\"], inplace=True)\n",
    "\n",
    "        # 获取列的总数\n",
    "        num_columns = len(df_kpi.columns)\n",
    "\n",
    "        # 创建新的列顺序：最后三列 + 所有其他列（除去最后三列）\n",
    "        new_order = df_kpi.columns[-3:].tolist() + df_kpi.columns[:-3].tolist()\n",
    "\n",
    "        # 重新索引以更改列顺序\n",
    "        df_kpi = df_kpi[new_order]\n",
    "\n",
    "        # 转换特定列的数据类型\n",
    "        int_columns = df_kpi.loc[:, 'gNB请求释放的5QI为1的Flow数(R2035_003)[个]':'gNBRRC连接建立成功次数-moVideoCall(R1001_019)[次]'].columns\n",
    "        for col in int_columns:\n",
    "            df_kpi[col] = pd.to_numeric(df_kpi[col], errors='coerce').fillna(0).astype(float).astype(int)\n",
    "\n",
    "        float_columns = ['5QI为1的平均Flow数(K1009_001)[个]', '5QI为2的平均Flow数(K1009_002)[个]']\n",
    "        for col in float_columns:\n",
    "            df_kpi[col] = pd.to_numeric(df_kpi[col], errors='coerce').fillna(0).round(2)\n",
    "\n",
    "        # 删除 '小区名称' 列\n",
    "        df_kpi = df_kpi.drop(columns=['小区名称'])\n",
    "\n",
    "        # 单位从0.01KB改为KB\n",
    "        df_kpi['小区用户面RLC SDU上行尾包字节数(R1501_005)[0.01KByte]'] = df_kpi['小区用户面RLC SDU上行尾包字节数(R1501_005)[0.01KByte]'] / 100\n",
    "        df_kpi['小区用户面RLC SDU下行尾包字节数(R1501_006)[0.01KByte]'] = df_kpi['小区用户面RLC SDU下行尾包字节数(R1501_006)[0.01KByte]'] / 100\n",
    "\n",
    "        # 定义函数来提取括号中的内容\n",
    "        def extract_code(column_name):\n",
    "            match = re.search(r'\\((.*?)\\)', column_name)\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "            return column_name\n",
    "\n",
    "        # 替换 DataFrame 的列名\n",
    "        df_kpi.columns = df_kpi.columns.to_series().apply(extract_code)\n",
    "\n",
    "        return df_kpi\n",
    "\n",
    "# 使用示例\n",
    "KPIDir = r'C:\\Users\\zhuak\\Desktop\\Geography\\MobileData'\n",
    "df_KPI = read_and_process_kpi_files(KPIDir)\n",
    "\n",
    "# 显示前10行数据\n",
    "if not df_KPI.empty:\n",
    "    print(df_KPI.head(10))\n",
    "else:\n",
    "    print(\"没有数据可显示。\")\n",
    "\n",
    "# 使用示例\n",
    "KPIDir = r'C:\\Users\\zhuak\\Desktop\\Geography\\MobileData'\n",
    "df_KPI = read_and_process_kpi_files(KPIDir)\n",
    "\n",
    "# 显示前10行数据\n",
    "if not df_KPI.empty:\n",
    "    print(df_KPI.head(10))\n",
    "else:\n",
    "    print(\"没有数据可显示。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB</th>\n",
       "      <th>nrCellCfg</th>\n",
       "      <th>开始时间</th>\n",
       "      <th>结束时间</th>\n",
       "      <th>Nr小区工作频段</th>\n",
       "      <th>MHz</th>\n",
       "      <th>逻辑小区id</th>\n",
       "      <th>R2035_003</th>\n",
       "      <th>R2035_013</th>\n",
       "      <th>R2035_026</th>\n",
       "      <th>...</th>\n",
       "      <th>R1001_001</th>\n",
       "      <th>R1001_004</th>\n",
       "      <th>R1001_007</th>\n",
       "      <th>R1001_008</th>\n",
       "      <th>R1001_012</th>\n",
       "      <th>R1001_015</th>\n",
       "      <th>R1001_018</th>\n",
       "      <th>R1001_019</th>\n",
       "      <th>K1009_001</th>\n",
       "      <th>K1009_002</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6299318</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-04</td>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>band28(758~803MHz)(28)</td>\n",
       "      <td>30(5)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>9884</td>\n",
       "      <td>2432</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>9848</td>\n",
       "      <td>2428</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>7.47</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6299318</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>band28(758~803MHz)(28)</td>\n",
       "      <td>30(5)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>9702</td>\n",
       "      <td>2508</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>9668</td>\n",
       "      <td>2505</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>5.65</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6299318</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>2024-09-07</td>\n",
       "      <td>band28(758~803MHz)(28)</td>\n",
       "      <td>30(5)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>14232</td>\n",
       "      <td>3982</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>14185</td>\n",
       "      <td>3978</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6299318</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-07</td>\n",
       "      <td>2024-09-08</td>\n",
       "      <td>band28(758~803MHz)(28)</td>\n",
       "      <td>30(5)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>17243</td>\n",
       "      <td>4610</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>17172</td>\n",
       "      <td>4600</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>11.19</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6299318</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-08</td>\n",
       "      <td>2024-09-09</td>\n",
       "      <td>band28(758~803MHz)(28)</td>\n",
       "      <td>30(5)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>13964</td>\n",
       "      <td>4258</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>13883</td>\n",
       "      <td>4248</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>6.63</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6299318</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-09</td>\n",
       "      <td>2024-09-10</td>\n",
       "      <td>band28(758~803MHz)(28)</td>\n",
       "      <td>30(5)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>10206</td>\n",
       "      <td>2876</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>10166</td>\n",
       "      <td>2867</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6299318</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-10</td>\n",
       "      <td>2024-09-11</td>\n",
       "      <td>band28(758~803MHz)(28)</td>\n",
       "      <td>30(5)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>13395</td>\n",
       "      <td>3690</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>13332</td>\n",
       "      <td>3681</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6299318</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-09-04</td>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>band28(758~803MHz)(28)</td>\n",
       "      <td>30(5)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>24187</td>\n",
       "      <td>4855</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>24102</td>\n",
       "      <td>4845</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>15.42</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6299318</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>band28(758~803MHz)(28)</td>\n",
       "      <td>30(5)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>26347</td>\n",
       "      <td>6148</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>26267</td>\n",
       "      <td>6141</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>14.45</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6299318</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>2024-09-07</td>\n",
       "      <td>band28(758~803MHz)(28)</td>\n",
       "      <td>30(5)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>227</td>\n",
       "      <td>...</td>\n",
       "      <td>28881</td>\n",
       "      <td>6504</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>28773</td>\n",
       "      <td>6495</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NB nrCellCfg        开始时间        结束时间                Nr小区工作频段    MHz  \\\n",
       "0  6299318         1  2024-09-04  2024-09-05  band28(758~803MHz)(28)  30(5)   \n",
       "1  6299318         1  2024-09-05  2024-09-06  band28(758~803MHz)(28)  30(5)   \n",
       "2  6299318         1  2024-09-06  2024-09-07  band28(758~803MHz)(28)  30(5)   \n",
       "3  6299318         1  2024-09-07  2024-09-08  band28(758~803MHz)(28)  30(5)   \n",
       "4  6299318         1  2024-09-08  2024-09-09  band28(758~803MHz)(28)  30(5)   \n",
       "5  6299318         1  2024-09-09  2024-09-10  band28(758~803MHz)(28)  30(5)   \n",
       "6  6299318         1  2024-09-10  2024-09-11  band28(758~803MHz)(28)  30(5)   \n",
       "7  6299318         2  2024-09-04  2024-09-05  band28(758~803MHz)(28)  30(5)   \n",
       "8  6299318         2  2024-09-05  2024-09-06  band28(758~803MHz)(28)  30(5)   \n",
       "9  6299318         2  2024-09-06  2024-09-07  band28(758~803MHz)(28)  30(5)   \n",
       "\n",
       "   逻辑小区id  R2035_003  R2035_013  R2035_026  ...  R1001_001  R1001_004  \\\n",
       "0     1.0          1          1         46  ...       9884       2432   \n",
       "1     1.0          2          2         61  ...       9702       2508   \n",
       "2     1.0          3          3         74  ...      14232       3982   \n",
       "3     1.0          5          5        131  ...      17243       4610   \n",
       "4     1.0          2          2         53  ...      13964       4258   \n",
       "5     1.0          5          4         63  ...      10206       2876   \n",
       "6     1.0          3          3         63  ...      13395       3690   \n",
       "7     2.0         10         10        179  ...      24187       4855   \n",
       "8     2.0         13         13        210  ...      26347       6148   \n",
       "9     2.0          7          7        227  ...      28881       6504   \n",
       "\n",
       "   R1001_007  R1001_008  R1001_012  R1001_015  R1001_018  R1001_019  \\\n",
       "0         98          0       9848       2428         98          0   \n",
       "1        100          0       9668       2505        100          0   \n",
       "2        125          0      14185       3978        125          0   \n",
       "3        137          0      17172       4600        136          0   \n",
       "4        125          0      13883       4248        124          0   \n",
       "5         84          0      10166       2867         84          0   \n",
       "6        102          0      13332       3681        102          0   \n",
       "7        187          0      24102       4845        186          0   \n",
       "8        213          0      26267       6141        213          0   \n",
       "9        229          0      28773       6495        228          0   \n",
       "\n",
       "   K1009_001  K1009_002  \n",
       "0       7.47       0.21  \n",
       "1       5.65       0.36  \n",
       "2       8.54       0.32  \n",
       "3      11.19       0.60  \n",
       "4       6.63       0.36  \n",
       "5       3.54       0.20  \n",
       "6       4.52       0.30  \n",
       "7      15.42       0.56  \n",
       "8      14.45       0.69  \n",
       "9      17.00       0.80  \n",
       "\n",
       "[10 rows x 245 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_KPI.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transport NAS MariaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database NewDBone created or already exists.\n",
      "Table NetworkPerformance created or already exists.\n",
      "Data uploaded successfully to table NetworkPerformance in database NewDBone.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine, text, Table, Column, MetaData, String, Integer, Float, Date\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from sqlalchemy.pool import QueuePool\n",
    "import time\n",
    "\n",
    "# 数据库连接信息\n",
    "DB_USER = 'root'\n",
    "DB_PASSWORD = 'root1234'\n",
    "DB_HOST = '27.16.178.213'\n",
    "DB_PORT = 3306\n",
    "DB_NAME = 'NewDBone'\n",
    "TABLE_NAME = 'NetworkPerformance'\n",
    "\n",
    "def create_db_engine(user, password, host, port, db_name=None, charset='utf8mb4'):\n",
    "    \"\"\"\n",
    "    创建数据库引擎\n",
    "    \"\"\"\n",
    "    if db_name:\n",
    "        connection_string = f\"mysql+pymysql://{user}:{password}@{host}:{port}/{db_name}?charset={charset}\"\n",
    "    else:\n",
    "        connection_string = f\"mysql+pymysql://{user}:{password}@{host}:{port}?charset={charset}\"\n",
    "    \n",
    "    return create_engine(connection_string, poolclass=QueuePool, pool_size=5, max_overflow=10, pool_timeout=30, pool_recycle=3600)\n",
    "\n",
    "def create_database(engine, db_name):\n",
    "    \"\"\"\n",
    "    创建数据库（如果不存在）\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        try:\n",
    "            connection.execute(text(f\"CREATE DATABASE IF NOT EXISTS {db_name} CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci\"))\n",
    "            print(f\"Database {db_name} created or already exists.\")\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"Error creating database: {e}\")\n",
    "            exit(1)\n",
    "\n",
    "def generate_table_columns(df):\n",
    "    \"\"\"\n",
    "    根据DataFrame生成数据表的列定义\n",
    "    \"\"\"\n",
    "    columns = []\n",
    "    for column_name, dtype in df.dtypes.items():\n",
    "        if pd.api.types.is_integer_dtype(dtype):\n",
    "            columns.append(Column(column_name, Integer))\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            columns.append(Column(column_name, Float))\n",
    "        elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "            columns.append(Column(column_name, Date))\n",
    "        else:\n",
    "            columns.append(Column(column_name, String(255)))\n",
    "    return columns\n",
    "\n",
    "def create_table(engine, table_name, columns):\n",
    "    \"\"\"\n",
    "    创建数据表（如果不存在）\n",
    "    \"\"\"\n",
    "    metadata = MetaData()\n",
    "    table = Table(table_name, metadata, *columns, mysql_charset='utf8mb4')\n",
    "    with engine.connect() as connection:\n",
    "        try:\n",
    "            table.create(connection, checkfirst=True)\n",
    "            print(f\"Table {table_name} created or already exists.\")\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"Error creating table: {e}\")\n",
    "            exit(1)\n",
    "    return table\n",
    "\n",
    "def upload_data_to_table(df, table_name, engine, columns):\n",
    "    \"\"\"\n",
    "    上传数据到数据表\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df.to_sql(table_name, con=engine, if_exists='append', index=False, dtype={col.name: col.type for col in columns})\n",
    "        print(f\"Data uploaded successfully to table {table_name} in database {DB_NAME}.\")\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Error uploading data: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "# 创建数据库引擎（不指定数据库）\n",
    "engine = create_db_engine(DB_USER, DB_PASSWORD, DB_HOST, DB_PORT)\n",
    "\n",
    "# 创建数据库（如果不存在）\n",
    "create_database(engine, DB_NAME)\n",
    "\n",
    "# 使用新创建的数据库\n",
    "engine = create_db_engine(DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_NAME)\n",
    "\n",
    "# 自动生成数据表的列定义\n",
    "columns = generate_table_columns(df_KPI)\n",
    "\n",
    "# 创建数据表（如果不存在）\n",
    "table = create_table(engine, TABLE_NAME, columns)\n",
    "\n",
    "# 上传数据到数据表\n",
    "upload_data_to_table(df_KPI, TABLE_NAME, engine, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>网元标识</th>\n",
       "      <th>小区本地ID</th>\n",
       "      <th>小区友好名</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>省份</th>\n",
       "      <th>地市</th>\n",
       "      <th>县区</th>\n",
       "      <th>镇区</th>\n",
       "      <th>村区</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6334965</td>\n",
       "      <td>0</td>\n",
       "      <td>房县小草咖啡1-D5H-2611</td>\n",
       "      <td>110.744614</td>\n",
       "      <td>32.068618</td>\n",
       "      <td>湖北省</td>\n",
       "      <td>十堰市</td>\n",
       "      <td>房县</td>\n",
       "      <td>城关镇</td>\n",
       "      <td>北关社区</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6334965</td>\n",
       "      <td>1</td>\n",
       "      <td>房县小草咖啡1-D5H-2612</td>\n",
       "      <td>110.744614</td>\n",
       "      <td>32.068618</td>\n",
       "      <td>湖北省</td>\n",
       "      <td>十堰市</td>\n",
       "      <td>房县</td>\n",
       "      <td>城关镇</td>\n",
       "      <td>北关社区</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>6334987</td>\n",
       "      <td>1</td>\n",
       "      <td>房县小草咖啡2-D5H-2612</td>\n",
       "      <td>110.744426</td>\n",
       "      <td>32.065918</td>\n",
       "      <td>湖北省</td>\n",
       "      <td>十堰市</td>\n",
       "      <td>房县</td>\n",
       "      <td>城关镇</td>\n",
       "      <td>北关社区</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>6334987</td>\n",
       "      <td>0</td>\n",
       "      <td>房县小草咖啡2-D5H-2611</td>\n",
       "      <td>110.744426</td>\n",
       "      <td>32.065918</td>\n",
       "      <td>湖北省</td>\n",
       "      <td>十堰市</td>\n",
       "      <td>房县</td>\n",
       "      <td>城关镇</td>\n",
       "      <td>北关社区</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>6337299</td>\n",
       "      <td>3</td>\n",
       "      <td>房县滨河花园-D5H-2611</td>\n",
       "      <td>110.743071</td>\n",
       "      <td>32.062452</td>\n",
       "      <td>湖北省</td>\n",
       "      <td>十堰市</td>\n",
       "      <td>房县</td>\n",
       "      <td>城关镇</td>\n",
       "      <td>北关社区</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         网元标识  小区本地ID             小区友好名   Longitude   Latitude   省份   地市  县区  \\\n",
       "0     6334965       0  房县小草咖啡1-D5H-2611  110.744614  32.068618  湖北省  十堰市  房县   \n",
       "1     6334965       1  房县小草咖啡1-D5H-2612  110.744614  32.068618  湖北省  十堰市  房县   \n",
       "574   6334987       1  房县小草咖啡2-D5H-2612  110.744426  32.065918  湖北省  十堰市  房县   \n",
       "575   6334987       0  房县小草咖啡2-D5H-2611  110.744426  32.065918  湖北省  十堰市  房县   \n",
       "3876  6337299       3   房县滨河花园-D5H-2611  110.743071  32.062452  湖北省  十堰市  房县   \n",
       "\n",
       "       镇区    村区  \n",
       "0     城关镇  北关社区  \n",
       "1     城关镇  北关社区  \n",
       "574   城关镇  北关社区  \n",
       "575   城关镇  北关社区  \n",
       "3876  城关镇  北关社区  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 定义保存路径和文件名\n",
    "GosDir = r'C:\\Users\\zhuak\\Desktop\\Geography'\n",
    "file_name = 'gdf_RAC.xlsx'\n",
    "file_path = os.path.join(GosDir, file_name)\n",
    "\n",
    "# 保存为 Excel 文件\n",
    "gdf_RAC.to_excel(file_path, index=False)\n",
    "gdf_RAC.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
